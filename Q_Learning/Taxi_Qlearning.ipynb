{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oy-Z0jzb91gM",
    "outputId": "a34c5953-4ca7-4780-b410-ceac891c5b06"
   },
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cYkNBuXw96a7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFRaQrgV-EJ1",
    "outputId": "07b023d1-cdff-4926-82f6-58e38a685f60"
   },
   "outputs": [],
   "source": [
    "# Virtual display\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W3Bqz2xx-FlX",
    "outputId": "b1f0c276-a275-4a57-bec1-196fa9ddf0c2"
   },
   "outputs": [],
   "source": [
    "!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nl6-hDL--HGV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import imageio\n",
    "import os\n",
    "import tqdm\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PW7Ntq7t-Jnx"
   },
   "outputs": [],
   "source": [
    "env =gym.make(\"Taxi-v3\" , render_mode = \"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Rn2ul94-VZJ",
    "outputId": "a1107ae8-fdee-47e0-fae7-a14aab8e4ce6"
   },
   "outputs": [],
   "source": [
    "state_space = env.observation_space.n\n",
    "action_space = env.action_space.n\n",
    "print(\"State space:\", state_space)\n",
    "print(\"action space:\", action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzu9ZUuf-pss"
   },
   "source": [
    "possible actions to be taken:\n",
    "\n",
    "0: move south\n",
    "\n",
    "1: move north\n",
    "\n",
    "2: move east\n",
    "\n",
    "3: move west\n",
    "\n",
    "4: pickup passenger\n",
    "\n",
    "5: drop off passenger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3N9MH9BA-0js"
   },
   "source": [
    "reward function:\n",
    "\n",
    "-1 per step unless other reward is triggered.\n",
    "\n",
    "+20 delivering passenger.\n",
    "\n",
    "-10 executing “pickup” and “drop-off” actions illegally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oumHr-8b_dhl"
   },
   "outputs": [],
   "source": [
    "def initialize_q_table(state_space , action_space):\n",
    "  Qtable = np.zeros((state_space , action_space))\n",
    "  return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v64k3oKL-dBr"
   },
   "outputs": [],
   "source": [
    "Qtable_taxi = initialize_q_table(state_space , action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PY4jVu7AD4C"
   },
   "outputs": [],
   "source": [
    "def greedy_policy(Qtable , state):\n",
    "  action =  np.argmax(Qtable[state][:])\n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JbVsO86_b0K"
   },
   "outputs": [],
   "source": [
    "def epsilon_greedy(Q, state, epsilon):\n",
    "    if np.random.random() < epsilon:\n",
    "        return np.random.randint(Q.shape[1])  # random action\n",
    "    else:\n",
    "        return np.argmax(Q[state])  # greedy action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I629OX2PC4-2"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_training_episodes = 25000   # Total training episodes\n",
    "learning_rate = 0.7           # Learning rate\n",
    "\n",
    "# Evaluation parameters\n",
    "n_eval_episodes = 100        # Total number of test episodes\n",
    "\n",
    "eval_seed = [16,54,165,177,191,191,120,80,149,178,48,38,6,125,174,73,50,172,100,148,146,6,25,40,68,148,49,167,9,97,164,176,61,7,54,55,\n",
    " 161,131,184,51,170,12,120,113,95,126,51,98,36,135,54,82,45,95,89,59,95,124,9,113,58,85,51,134,121,169,105,21,30,11,50,65,12,43,82,145,152,97,106,55,31,85,38,\n",
    " 112,102,168,123,97,21,83,158,26,80,63,5,81,32,11,28,148] # Evaluation seed, this ensures that all classmates agents are trained on the same taxi starting position\n",
    "                                                          # Each seed has a specific starting state\n",
    "\n",
    "# Environment parameters\n",
    "env_id = \"Taxi-v3\"           # Name of the environment\n",
    "max_steps = 99               # Max steps per episode\n",
    "gamma = 0.95                 # Discounting rate\n",
    "\n",
    "# Exploration parameters\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.05           # Minimum exploration probability\n",
    "decay_rate = 0.005            # Exponential decay rate for exploration prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ool2tN3PAcVE"
   },
   "outputs": [],
   "source": [
    "def train(Qtable , min_epsilon , max_epsilon ,decay ,max_steps , n_training_episodes, env):\n",
    "  for episode in tqdm(range(n_training_episodes)):\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * episode)\n",
    "\n",
    "    state , info = env.reset()\n",
    "    step = 0\n",
    "    truncated = False\n",
    "    terminated = False\n",
    "\n",
    "    for step in range(max_steps):\n",
    "      action = epsilon_greedy(Qtable , state , epsilon)\n",
    "\n",
    "      new_state , reward , terminated , truncated , info = env.step(action)\n",
    "\n",
    "      Qtable[state][action] = Qtable[state][action] + learning_rate*(reward  + gamma*np.max(Qtable[new_state]) - Qtable[state][action])\n",
    "\n",
    "      if terminated or truncated:\n",
    "        break\n",
    "      state = new_state\n",
    "  return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "2b384f189c3042ea884fc727fafd4775",
      "7607240e2e1c4eb1adf632405c45fd16",
      "b9e3ef64ac954faa8d1fce944803d30e",
      "f78ba19eba9e4d01b1d16efb4683bbc8",
      "36f05dfc1ab54a41a93695bc7f962ffb",
      "5ccaec56152d48a2a82947566b0bd424",
      "c8bd7db4f90b4c238bbdc56c948d6729",
      "0f1ba9e6bcc247b3af93f7aa802642c8",
      "5fdece6cb83441429a0fa272faa37464",
      "9aeb3b90594341a39fe1c0049b79eca3",
      "04544b65a3a049078320e9a44ffac998"
     ]
    },
    "id": "kAVN6jhXCoca",
    "outputId": "3cd8d38a-3062-4774-fb50-3219c3c817b3"
   },
   "outputs": [],
   "source": [
    "Qtable_taxi = train(Qtable_taxi , min_epsilon , max_epsilon ,decay_rate  , max_steps, n_training_episodes, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aebfc953"
   },
   "outputs": [],
   "source": [
    "def evaluate_agent(env, max_steps, n_eval_episodes, Q, seed):\n",
    "  \"\"\"\n",
    "  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n",
    "  :param env: The evaluation environment\n",
    "  :param max_steps: Maximum number of steps per episode\n",
    "  :param n_eval_episodes: Number of episode to evaluate the agent\n",
    "  :param Q: The Q-table\n",
    "  :param seed: The evaluation seed array (for taxi-v3)\n",
    "  \"\"\"\n",
    "  episode_rewards = []\n",
    "  for episode in tqdm(range(n_eval_episodes)):\n",
    "    if seed:\n",
    "      state, info = env.reset(seed=seed[episode])\n",
    "    else:\n",
    "      state, info = env.reset()\n",
    "    step = 0\n",
    "    truncated = False\n",
    "    terminated = False\n",
    "    total_rewards_ep = 0\n",
    "\n",
    "    for step in range(max_steps):\n",
    "      # Take the action (index) that have the maximum expected future reward given that state\n",
    "      action = greedy_policy(Q, state)\n",
    "      new_state, reward, terminated, truncated, info = env.step(action)\n",
    "      total_rewards_ep += reward\n",
    "\n",
    "      if terminated or truncated:\n",
    "        break\n",
    "      state = new_state\n",
    "    episode_rewards.append(total_rewards_ep)\n",
    "  mean_reward = np.mean(episode_rewards)\n",
    "  std_reward = np.std(episode_rewards)\n",
    "\n",
    "  return mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "9d708a885f6e41abaa8e2f90ed3bf64f",
      "f93f1efeecdc423ea6f7f09517ec7d59",
      "588bc85cc6b24df7baf9ebeca2b927a1",
      "7d8018ae313b459c96fd97d74c1093bb",
      "1759a890a50e49de8da78b969c946520",
      "1431065d6c2c482da79c7d05e236fca0",
      "d069c0f13e184be8a0f8efbf58b8647d",
      "484fbea3dc344a0fa1a1252cc5e7732a",
      "9107a324d6fb485eb39f66b2cad0e77c",
      "938f6f8450e945fd893a32ea41f64fa2",
      "cc52c30ac16d4f29ab15eab12977a9cc"
     ]
    },
    "id": "476b9b7d",
    "outputId": "9cc36740-accb-46eb-9624-da4f473a2789"
   },
   "outputs": [],
   "source": [
    "# Evaluate our Agent\n",
    "mean_reward, std_reward = evaluate_agent(env, max_steps, n_eval_episodes, Qtable_taxi, eval_seed)\n",
    "print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RG_gR0TtHv1s"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, snapshot_download\n",
    "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQDUHp8GHykd"
   },
   "outputs": [],
   "source": [
    "def record_video(env, Qtable, out_directory, fps=1):\n",
    "  \"\"\"\n",
    "  Generate a replay video of the agent\n",
    "  :param env\n",
    "  :param Qtable: Qtable of our agent\n",
    "  :param out_directory\n",
    "  :param fps: how many frame per seconds (with taxi-v3 and frozenlake-v1 we use 1)\n",
    "  \"\"\"\n",
    "  images = []\n",
    "  terminated = False\n",
    "  truncated = False\n",
    "  state, info = env.reset(seed=random.randint(0,500))\n",
    "  img = env.render()\n",
    "  images.append(img)\n",
    "  while not terminated or truncated:\n",
    "    # Take the action (index) that have the maximum expected future reward given that state\n",
    "    action = np.argmax(Qtable[state][:])\n",
    "    state, reward, terminated, truncated, info = env.step(action) # We directly put next_state = state for recording logic\n",
    "    img = env.render()\n",
    "    images.append(img)\n",
    "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FsHy2TXiH0f3"
   },
   "outputs": [],
   "source": [
    "def push_to_hub(\n",
    "    repo_id, model, env, video_fps=1, local_repo_path=\"hub\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate, Generate a video and Upload a model to Hugging Face Hub.\n",
    "    This method does the complete pipeline:\n",
    "    - It evaluates the model\n",
    "    - It generates the model card\n",
    "    - It generates a replay video of the agent\n",
    "    - It pushes everything to the Hub\n",
    "\n",
    "    :param repo_id: repo_id: id of the model repository from the Hugging Face Hub\n",
    "    :param env\n",
    "    :param video_fps: how many frame per seconds to record our video replay\n",
    "    (with taxi-v3 and frozenlake-v1 we use 1)\n",
    "    :param local_repo_path: where the local repository is\n",
    "    \"\"\"\n",
    "    _, repo_name = repo_id.split(\"/\")\n",
    "\n",
    "    eval_env = env\n",
    "    api = HfApi()\n",
    "\n",
    "    # Step 1: Create the repo\n",
    "    repo_url = api.create_repo(\n",
    "        repo_id=repo_id,\n",
    "        exist_ok=True,\n",
    "    )\n",
    "\n",
    "    # Step 2: Download files\n",
    "    repo_local_path = Path(snapshot_download(repo_id=repo_id))\n",
    "\n",
    "    # Step 3: Save the model\n",
    "    if env.spec.kwargs.get(\"map_name\"):\n",
    "        model[\"map_name\"] = env.spec.kwargs.get(\"map_name\")\n",
    "        if env.spec.kwargs.get(\"is_slippery\", \"\") == False:\n",
    "            model[\"slippery\"] = False\n",
    "\n",
    "    # Pickle the model\n",
    "    with open((repo_local_path) / \"q-learning.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    # Step 4: Evaluate the model and build JSON with evaluation metrics\n",
    "    mean_reward, std_reward = evaluate_agent(\n",
    "        eval_env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"]\n",
    "    )\n",
    "\n",
    "    evaluate_data = {\n",
    "        \"env_id\": model[\"env_id\"],\n",
    "        \"mean_reward\": mean_reward,\n",
    "        \"n_eval_episodes\": model[\"n_eval_episodes\"],\n",
    "        \"eval_datetime\": datetime.datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "    # Write a JSON file called \"results.json\" that will contain the\n",
    "    # evaluation results\n",
    "    with open(repo_local_path / \"results.json\", \"w\") as outfile:\n",
    "        json.dump(evaluate_data, outfile)\n",
    "\n",
    "    # Step 5: Create the model card\n",
    "    env_name = model[\"env_id\"]\n",
    "    if env.spec.kwargs.get(\"map_name\"):\n",
    "        env_name += \"-\" + env.spec.kwargs.get(\"map_name\")\n",
    "\n",
    "    if env.spec.kwargs.get(\"is_slippery\", \"\") == False:\n",
    "        env_name += \"-\" + \"no_slippery\"\n",
    "\n",
    "    metadata = {}\n",
    "    metadata[\"tags\"] = [env_name, \"q-learning\", \"reinforcement-learning\", \"custom-implementation\"]\n",
    "\n",
    "    # Add metrics\n",
    "    eval = metadata_eval_result(\n",
    "        model_pretty_name=repo_name,\n",
    "        task_pretty_name=\"reinforcement-learning\",\n",
    "        task_id=\"reinforcement-learning\",\n",
    "        metrics_pretty_name=\"mean_reward\",\n",
    "        metrics_id=\"mean_reward\",\n",
    "        metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
    "        dataset_pretty_name=env_name,\n",
    "        dataset_id=env_name,\n",
    "    )\n",
    "\n",
    "    # Merges both dictionaries\n",
    "    metadata = {**metadata, **eval}\n",
    "\n",
    "    model_card = f\"\"\"\n",
    "  # **Q-Learning** Agent playing1 **{env_id}**\n",
    "  This is a trained model of a **Q-Learning** agent playing **{env_id}** .\n",
    "\n",
    "  ## Usage\n",
    "\n",
    "  ```python\n",
    "\n",
    "  model = load_from_hub(repo_id=\"{repo_id}\", filename=\"q-learning.pkl\")\n",
    "\n",
    "  # Don't forget to check if you need to add additional attributes (is_slippery=False etc)\n",
    "  env = gym.make(model[\"env_id\"])\n",
    "  ```\n",
    "  \"\"\"\n",
    "\n",
    "    evaluate_agent(env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"])\n",
    "\n",
    "    readme_path = repo_local_path / \"README.md\"\n",
    "    readme = \"\"\n",
    "    print(readme_path.exists())\n",
    "    if readme_path.exists():\n",
    "        with readme_path.open(\"r\", encoding=\"utf8\") as f:\n",
    "            readme = f.read()\n",
    "    else:\n",
    "        readme = model_card\n",
    "\n",
    "    with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(readme)\n",
    "\n",
    "    # Save our metrics to Readme metadata\n",
    "    metadata_save(readme_path, metadata)\n",
    "\n",
    "    # Step 6: Record a video\n",
    "    video_path = repo_local_path / \"replay.mp4\"\n",
    "    record_video(env, model[\"qtable\"], video_path, video_fps)\n",
    "\n",
    "    # Step 7. Push everything to the Hub\n",
    "    api.upload_folder(\n",
    "        repo_id=repo_id,\n",
    "        folder_path=repo_local_path,\n",
    "        path_in_repo=\".\",\n",
    "    )\n",
    "\n",
    "    print(\"Your model is pushed to the Hub. You can view your model here: \", repo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331,
     "referenced_widgets": [
      "f1b3831fc2fa426c8decc333778dd05c",
      "b0f963d891d041a6bf7ca46381112125",
      "daf7c441747b4c0fadc3ba2fbc0372c9",
      "fc3f286ec9e9471e952ba4bfda0ad063",
      "88353c68db5645ac8c5d8ceb72513458",
      "638ed7ce3f134ddaa2f17ca6b8d8643b",
      "b28b0c376a084a95bcfbb5fe94d89001",
      "2ec6e3851ee84f7f999cac9a3a971752",
      "a0f73fb9649543e69b762eaa39a81a77",
      "f44e99886e954ab5a640cf2a6bf8e27f",
      "3109d9aabd5b40388a1a44e77f1624d0",
      "626c914ddedb4f0289f55e15352350e9",
      "e3bdff1351b94ede8ec5753493fdb7a4",
      "2d75b18a2aa248259acb25f7bc81ca51",
      "b56cc27e0088469ebea6fb127442ac36",
      "67021edd0b9d43b0a5d467e247760faf",
      "2dc420e79cd84f9897bc358937b2a76c"
     ]
    },
    "id": "VWs6R8SxH3Jb",
    "outputId": "9e834a06-856c-4e1b-8735-1078bd241412"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5L8CLP3HMDc"
   },
   "outputs": [],
   "source": [
    "model = {\n",
    "    \"env_id\": env_id,\n",
    "    \"max_steps\": max_steps,\n",
    "    \"n_training_episodes\": n_training_episodes,\n",
    "    \"n_eval_episodes\": n_eval_episodes,\n",
    "    \"eval_seed\": eval_seed,\n",
    "\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"gamma\": gamma,\n",
    "\n",
    "    \"max_epsilon\": max_epsilon,\n",
    "    \"min_epsilon\": min_epsilon,\n",
    "    \"decay_rate\": decay_rate,\n",
    "\n",
    "    \"qtable\": Qtable_taxi\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283,
     "referenced_widgets": [
      "ccc6702a917d4b63adcdcac1dbaa0f78",
      "850dc67bf7b54cc39f95fd0e2bf8c7f2",
      "566e670791cc4bd1b243a89589925953",
      "d25d9dbb92ce42b1968ad2a1ae2ef101",
      "2d854549c400491088726acc53cdde11",
      "3e0cbf11698f47079f4e2c17c6977502",
      "e00f41ea9b754a1381951da945e1cc83",
      "bb794af499e5432c9bb3a6ef5969cfdf",
      "d4b1397d6dde4df987a16072a9cc07ba",
      "72b5f069da354fb9857b189b20e344d6",
      "93d0e7e6875e4f1681887a8ef94744f2",
      "4381eb50d6d0437ab231aa4ad135fce6",
      "994a4c56ce3e4ec0bc54d098cb8187eb",
      "c2a414b122b84fb2920e3210cf5e046b",
      "0de263abf2ce4c79a5ad1a30fa61c4c5",
      "ec9251b02e6745e88d2d3b1fc6953937",
      "762686db0ebc4520bbc33a23796c8c13",
      "933f9e0ac03641a99325451674b657c1",
      "a90abbcdd93540879347cf97b4dd749d",
      "e60cf2e73bb747daa58f027c57a58735",
      "d216cc810de84628ad437458e3501f0e",
      "3d0436917fe84165bf69114e0c55bb6e",
      "8cd8b0a46bf245a3995adf0b807fc90f",
      "56d00a68bdc3422d915dee3eb4e2245e",
      "bba7961b7bde46f9a699515a576a1e3d",
      "6377d9d042484999a49f0b9cb74684dd",
      "bc4fb586f3204e95b710e2e0dad51659",
      "93b5184bd32f4dda8560e04c09357c61",
      "cb10b016797948eabf440c27390a158f",
      "4140e253a84b4a809dacd301fb3eeed5",
      "656f19e2584e4af19e7d44d1365e6bc7",
      "3741bcc779904202879a6fae0d7062d4",
      "63f1e258e4c740be9ac07b200f58ff47",
      "57db203e8492426ab837d13ab1f883fc",
      "3c47632633ca4988978e54994d07d393",
      "6c3b78be00494cdea865790f52e6650b",
      "d8c46752a4d04636896015e75ab1f709",
      "a9ccd5d5f5f94aa488056474b2a0a319",
      "4b178f97c1804e26a6d094b244aed9f6",
      "fc9fa08bfa7947b5815de1533eb5fc72",
      "0d6aa7575ae94f05821e38ec60d3b44d",
      "79c749745a7e41bf83ed11e96e7f31cf",
      "0057ae8be7a049f896ed646453148c93",
      "3bdc5857c563452b994685680efb029e",
      "3a97d535223245fe8c07466c8115101b",
      "940bae13bb2446a3ba02fb837bfc9df1",
      "ebe4898d546c4a23a8eaaf0515873f8c",
      "dd5c3ff6a3124bbf89c8d4fd6ee09167",
      "0013dad6a51a494f981505393b8a80c5",
      "9d06003fa37644eebc52406971b25972",
      "4c69bd91a8334be485ed3af7bae7ef73",
      "19a9718330094180b74a3b916d8eb48c",
      "9dbbf5bb61154dbf8c55cbc122608d6e",
      "0b6897a94abb432c8179041ad1cc3124",
      "668e5e322dfe4740a76a0870a0f3774c",
      "8d822dde8cff4763952e7b60a9e09ded",
      "5c8ab0cc03e24e6bbf11bba32e0a1e06",
      "acb16e944cc14a9594c68efe27c805b1",
      "1653553ce1b6461c9e41eab8f1f6d6ac",
      "096de16cbad148ed8214d8e94d9f3f0a",
      "9fb39673f4734beb919a827bbcd46549",
      "2caec612cf4d470aa957b07d6cee77cb",
      "0e298a90a60047789bbdac2e04bf9141",
      "dc8e30ae39274df987e0b3ce7127163e",
      "6d0a665d5c114e428ae70c409a4d8d5d",
      "1754f177999641f1955d3708dab3000c"
     ]
    },
    "id": "mXUKAo34HhS4",
    "outputId": "5a1ac6d3-47f1-4b58-f5a2-441ccdc1851d"
   },
   "outputs": [],
   "source": [
    "username = \"Hitesh7009\"\n",
    "repo_name = \"Taxi-v3\"\n",
    "push_to_hub(\n",
    "    repo_id=f\"{username}/{repo_name}\",\n",
    "    model=model,\n",
    "    env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzF9yE2MIJnw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
